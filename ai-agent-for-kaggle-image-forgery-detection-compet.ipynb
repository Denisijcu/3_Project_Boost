{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13860966,"sourceType":"datasetVersion","datasetId":8830376}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/denissanchez/ai-agent-for-kaggle-image-forgery-detection-compet?scriptVersionId=281614396\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from IPython.display import Image, display, HTML\n\n# T√≠tulo √©pico\ndisplay(HTML(\"\"\"\n<div style=\"text-align:center; padding:20px; background:#0f0f0f; border-radius:15px; margin:10px 0;\">\n    <h1 style=\"color:#00ff41; text-shadow: 0 0 10px #00ff41;\">IMAGE FORGERY ASSISTANT</h1>\n    <h2 style=\"color:#00ffff;\">Arquitectura Multiagente - Nivel 3</h2>\n</div>\n\"\"\"))\n\n# El gr√°fico\ndisplay(Image(filename=\"/kaggle/input/graph-01/grafico.png\", width=950))\n\n# Caption\ndisplay(HTML(\"\"\"\n<div style=\"text-align:center; color:#aaa; font-style:italic; margin-top:10px;\">\n    Sistema multiagente en producci√≥n ‚Ä¢ Gemini 2.0 Flash ‚Ä¢ 5 herramientas especializadas<br>\n    <strong>Ejemplo perfecto del Cap√≠tulo 4 del libro \"Agentes de IA: El Manual del Creador\"</strong>\n</div>\n\"\"\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nü§ñ IMAGE FORGERY ASSISTANT - INTERACTIVE DEMO\n================================================\nProduction-ready AI Agent for Kaggle Image Forgery Detection Competition\n\nFeatures:\n- Multi-agent system with specialized tools\n- Hybrid architecture (optimized for Kaggle)\n- Interactive chat interface\n- Real-time responses\n\nDeveloper: Denis\nCourse: Google/Kaggle 5-Day AI Agents Intensive\n\ngithub link https://github.com/Denisijcu/image-forgery-assistant.git\n\"\"\"\n\n# Install dependencies\n!pip install -q google-generativeai ipywidgets\n\nprint(\"‚úÖ Dependencies installed!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nImport required libraries\n\"\"\"\n\nimport os\nimport time\nimport json\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\n\n# Google Generative AI\nfrom google import genai\nfrom google.genai import types\n\n# Kaggle Secrets\nfrom kaggle_secrets import UserSecretsClient\n\n# Widgets for interactive chat\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output, HTML\n\nprint(\"‚úÖ Imports successful!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nAgent Configuration\n\"\"\"\n\n# Get API key from Kaggle Secrets\n# IMPORTANT: Add your GOOGLE_API_KEY in Kaggle Secrets first!\n# Go to: Add-ons ‚Üí Secrets ‚Üí Add Secret\n# Label: GOOGLE_API_KEY\n# Value: [your API key]\n\ntry:\n    user_secrets = UserSecretsClient()\n    GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n    print(\"‚úÖ API Key loaded from secrets!\")\nexcept:\n    print(\"‚ö†Ô∏è Warning: Could not load API key from secrets\")\n    print(\"Please add GOOGLE_API_KEY to Kaggle Secrets\")\n    GOOGLE_API_KEY = None\n\n# Agent Configuration\nAGENT_CONFIG = {\n    \"user_name\": \"Denis\",\n    \"competition\": \"Recod.ai/LUC Scientific Image Forgery Detection\",\n    \"current_model\": \"EfficientNet-B4 UNet++\",\n    \"current_score\": 0.303,\n    \"target_score\": 0.350,\n    \"version\": \"1.0.0\"\n}\n\n# Display configuration\nprint(\"\\n\" + \"=\"*70)\nprint(\"  üéØ AGENT CONFIGURATION\")\nprint(\"=\"*70)\nfor key, value in AGENT_CONFIG.items():\n    print(f\"  ‚Ä¢ {key}: {value}\")\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nLLM Interface - Optimized for Kaggle\nUses Gemini API (cloud-based, no local server needed)\n\"\"\"\n\nclass KaggleLLM:\n    \"\"\"\n    Simplified LLM for Kaggle environment\n    Uses Google Gemini API\n    \"\"\"\n    \n    def __init__(self, api_key: str):\n        if not api_key:\n            raise ValueError(\"API key is required\")\n        \n        self.client = genai.Client(api_key=api_key)\n        self.model = \"gemini-2.0-flash\"\n        self.call_count = 0\n        self.total_time = 0\n        \n        print(f\"‚úÖ LLM initialized with model: {self.model}\")\n    \n    def call(\n        self, \n        prompt: str, \n        max_tokens: int = 1000, \n        temperature: float = 0.3,\n        system_prompt: str = None\n    ) -> str:\n        \"\"\"\n        Call Gemini API\n        \n        Args:\n            prompt: User prompt\n            max_tokens: Maximum tokens to generate\n            temperature: Sampling temperature (0.0-1.0)\n            system_prompt: Optional system context\n        \n        Returns:\n            Generated text response\n        \"\"\"\n        try:\n            # Combine system prompt if provided\n            full_prompt = prompt\n            if system_prompt:\n                full_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n            \n            # Track timing\n            start_time = time.time()\n            \n            # Call API\n            response = self.client.models.generate_content(\n                model=self.model,\n                contents=full_prompt,\n                config=types.GenerateContentConfig(\n                    max_output_tokens=max_tokens,\n                    temperature=temperature\n                )\n            )\n            \n            # Update stats\n            elapsed = time.time() - start_time\n            self.call_count += 1\n            self.total_time += elapsed\n            \n            return response.text\n            \n        except Exception as e:\n            return f\"‚ùå Error calling LLM: {str(e)}\"\n    \n    def get_stats(self) -> dict:\n        \"\"\"Get LLM usage statistics\"\"\"\n        avg_time = self.total_time / self.call_count if self.call_count > 0 else 0\n        return {\n            \"total_calls\": self.call_count,\n            \"total_time\": round(self.total_time, 2),\n            \"avg_time\": round(avg_time, 2)\n        }\n\n\n# Initialize global LLM instance\nif GOOGLE_API_KEY:\n    llm = KaggleLLM(GOOGLE_API_KEY)\n    print(\"‚úÖ LLM ready to use!\")\nelse:\n    llm = None\n    print(\"‚ö†Ô∏è LLM not initialized - API key missing\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nAgent Tools - Specialized functions for competition tasks\n\"\"\"\n\ndef suggest_improvements(model_type: str, current_score: float, context: str = None) -> str:\n    \"\"\"\n    Suggest improvements for current model\n    \n    Args:\n        model_type: Current model architecture\n        current_score: Current competition score\n        context: Optional additional context\n    \n    Returns:\n        Detailed improvement suggestions\n    \"\"\"\n    context_section = \"\"\n    if context:\n        context_section = f\"\\n\\nAdditional context: {context}\"\n    \n    prompt = f\"\"\"You are an expert in image forgery detection and Kaggle competitions.\n\nCurrent model: {model_type}\nCurrent score: {current_score}\nTarget: 0.350+{context_section}\n\nProvide 3-5 specific, actionable improvements ranked by expected impact.\n\nFocus on:\n1. Architecture improvements\n2. Training techniques  \n3. Data augmentation\n4. Ensemble methods\n5. Post-processing\n\nBe specific and include implementation details.\"\"\"\n\n    return llm.call(prompt, max_tokens=1500)\n\n\ndef compare_architectures(arch1: str, arch2: str, context: str = None) -> str:\n    \"\"\"\n    Compare two model architectures\n    \n    Args:\n        arch1: First architecture\n        arch2: Second architecture\n        context: Optional additional context\n    \n    Returns:\n        Detailed comparison analysis\n    \"\"\"\n    context_section = \"\"\n    if context:\n        context_section = f\"\\n\\nAdditional context: {context}\"\n    \n    prompt = f\"\"\"Compare these architectures for image forgery detection:\n\nArchitecture 1: {arch1}\nArchitecture 2: {arch2}{context_section}\n\nProvide:\n1. Pros and cons of each\n2. Performance comparison\n3. Computational requirements\n4. Recommendation for Kaggle competition\n\nBe specific and data-driven.\"\"\"\n\n    return llm.call(prompt, max_tokens=1500)\n\n\ndef debug_rle_masks(error_description: str, code_snippet: str = None) -> str:\n    \"\"\"\n    Debug RLE mask encoding issues\n    \n    Args:\n        error_description: Description of the error\n        code_snippet: Optional code snippet with the issue\n    \n    Returns:\n        Debugging suggestions and solutions\n    \"\"\"\n    code_section = \"\"\n    if code_snippet:\n        code_section = f\"\\n\\nCode snippet:\\n```python\\n{code_snippet}\\n```\"\n    \n    prompt = f\"\"\"Debug RLE mask encoding for COCO format:\n\nError: {error_description}{code_section}\n\nProvide:\n1. Root cause analysis\n2. Corrected code\n3. Validation approach\n4. Common pitfalls to avoid\n\nFocus on COCO RLE standard compliance.\"\"\"\n\n    return llm.call(prompt, max_tokens=1500)\n\n\ndef create_strategy_plan(goal: str, timeframe: str, current_state: str = None) -> str:\n    \"\"\"\n    Create strategic plan to reach goal\n    \n    Args:\n        goal: Target goal\n        timeframe: Time available\n        current_state: Optional current state description\n    \n    Returns:\n        Detailed strategic plan\n    \"\"\"\n    current_state_text = current_state or \"Not specified\"\n    \n    prompt = f\"\"\"Create a detailed action plan:\n\nGoal: {goal}\nTimeframe: {timeframe}\nCurrent state: {current_state_text}\n\nProvide:\n1. Day-by-day breakdown\n2. Specific tasks with time estimates\n3. Success metrics\n4. Risk mitigation\n5. Contingency plans\n\nBe realistic and actionable.\"\"\"\n\n    return llm.call(prompt, max_tokens=1500)\n\n\ndef analyze_discussions(topic: str, num_discussions: int = 5) -> str:\n    \"\"\"\n    Analyze Kaggle discussion insights\n    \n    Args:\n        topic: Discussion topic\n        num_discussions: Number of discussions to consider\n    \n    Returns:\n        Analysis and insights\n    \"\"\"\n    prompt = f\"\"\"Analyze Kaggle competition discussions about: {topic}\n\nNumber of discussions to consider: {num_discussions}\n\nProvide:\n1. Key insights and techniques\n2. Common approaches\n3. Tips from top performers\n4. Code snippets (if relevant)\n5. Actionable recommendations\n\nSynthesize information concisely.\"\"\"\n\n    return llm.call(prompt, max_tokens=1500)\n\n\n# Tools registry\nTOOLS = {\n    \"suggest_improvements\": {\n        \"function\": suggest_improvements,\n        \"description\": \"Suggests improvements for the current model\",\n        \"parameters\": [\"model_type\", \"current_score\"],\n        \"optional\": [\"context\"]\n    },\n    \"compare_architectures\": {\n        \"function\": compare_architectures,\n        \"description\": \"Compares two model architectures\",\n        \"parameters\": [\"arch1\", \"arch2\"],\n        \"optional\": [\"context\"]\n    },\n    \"debug_rle_masks\": {\n        \"function\": debug_rle_masks,\n        \"description\": \"Debugs RLE mask encoding issues\",\n        \"parameters\": [\"error_description\"],\n        \"optional\": [\"code_snippet\"]\n    },\n    \"create_strategy_plan\": {\n        \"function\": create_strategy_plan,\n        \"description\": \"Creates a strategic plan to reach a goal\",\n        \"parameters\": [\"goal\", \"timeframe\"],\n        \"optional\": [\"current_state\"]\n    },\n    \"analyze_discussions\": {\n        \"function\": analyze_discussions,\n        \"description\": \"Analyzes Kaggle discussion insights\",\n        \"parameters\": [\"topic\"],\n        \"optional\": [\"num_discussions\"]\n    }\n}\n\nprint(f\"‚úÖ {len(TOOLS)} tools loaded and ready!\")\nprint(\"\\nAvailable tools:\")\nfor name, info in TOOLS.items():\n    print(f\"  ‚Ä¢ {name}: {info['description']}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nMain Agent - Coordinates tools and provides intelligent responses\n\"\"\"\n\nclass ImageForgeryAgent:\n    \"\"\"\n    Main agent for Image Forgery Detection competition\n    Simplified version optimized for Kaggle\n    \"\"\"\n    \n    def __init__(self, config: dict, llm_instance):\n        self.config = config\n        self.llm = llm_instance\n        self.query_count = 0\n        self.successful_queries = 0\n        \n        print(\"‚úÖ Agent initialized!\")\n    \n    def run(self, query: str, context: str = None) -> str:\n        \"\"\"\n        Process user query\n        \n        Args:\n            query: User question or request\n            context: Optional additional context\n        \n        Returns:\n            Agent response\n        \"\"\"\n        self.query_count += 1\n        \n        try:\n            # Build system context\n            system_context = f\"\"\"You are the Image Forgery Competition Assistant for {self.config['user_name']}.\n\nCompetition: {self.config['competition']}\nCurrent model: {self.config['current_model']}\nCurrent score: {self.config['current_score']}\nTarget score: {self.config['target_score']}\n\nAvailable tools:\n- suggest_improvements - Model optimization suggestions\n- compare_architectures - Architecture comparison analysis\n- debug_rle_masks - RLE encoding debugging\n- create_strategy_plan - Strategic planning\n- analyze_discussions - Competition insights analysis\n\nYour job is to:\n1. Understand the user's query\n2. Provide helpful, specific, actionable guidance\n3. Use your expertise in image forgery detection\n4. Focus on practical Kaggle competition strategies\"\"\"\n\n            # Add context if provided\n            if context:\n                system_context += f\"\\n\\nAdditional context: {context}\"\n            \n            # Build prompt\n            prompt = f\"\"\"{system_context}\n\nUser query: {query}\n\nProvide a helpful, detailed response:\"\"\"\n            \n            # Get response\n            response = self.llm.call(prompt, max_tokens=2000, temperature=0.3)\n            \n            self.successful_queries += 1\n            return response\n            \n        except Exception as e:\n            return f\"‚ùå Error processing query: {str(e)}\"\n    \n    def get_stats(self) -> dict:\n        \"\"\"Get agent statistics\"\"\"\n        success_rate = (self.successful_queries / self.query_count * 100) if self.query_count > 0 else 0\n        \n        return {\n            \"total_queries\": self.query_count,\n            \"successful_queries\": self.successful_queries,\n            \"success_rate\": round(success_rate, 1),\n            \"llm_stats\": self.llm.get_stats()\n        }\n    \n    def show_tools(self):\n        \"\"\"Display available tools\"\"\"\n        print(\"\\nüìã Available Tools:\")\n        print(\"=\"*70)\n        for name, info in TOOLS.items():\n            print(f\"\\nüîß {name}\")\n            print(f\"   Description: {info['description']}\")\n            print(f\"   Parameters: {', '.join(info['parameters'])}\")\n            if info.get('optional'):\n                print(f\"   Optional: {', '.join(info['optional'])}\")\n        print(\"=\"*70)\n\n\n# Initialize agent\nif llm:\n    agent = ImageForgeryAgent(AGENT_CONFIG, llm)\n    print(\"\\n‚úÖ Agent ready to help with your competition!\")\nelse:\n    agent = None\n    print(\"\\n‚ö†Ô∏è Agent not initialized - LLM unavailable\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nInteractive Chat Interface using ipywidgets\nBeautiful, professional chat UI for Kaggle\n\"\"\"\n\nclass KaggleChat:\n    \"\"\"\n    Interactive chat interface with widgets\n    Provides a professional chat experience in Kaggle notebooks\n    \"\"\"\n    \n    def __init__(self, agent_instance):\n        if not agent_instance:\n            raise ValueError(\"Agent instance is required\")\n        \n        self.agent = agent_instance\n        self.conversation_history = []\n        \n        # Create widgets\n        self._create_widgets()\n        self._setup_handlers()\n        \n        print(\"‚úÖ Chat interface ready!\")\n    \n    def _create_widgets(self):\n        \"\"\"Create UI widgets\"\"\"\n        # Output area for chat history\n        self.output = widgets.Output(\n            layout=widgets.Layout(\n                height='400px',\n                overflow_y='auto',\n                border='1px solid #ddd',\n                padding='10px'\n            )\n        )\n        \n        # Input text box\n        self.input_box = widgets.Text(\n            placeholder='Type your question here... (press Enter to send)',\n            description='',\n            layout=widgets.Layout(width='75%', height='40px')\n        )\n        \n        # Send button\n        self.send_button = widgets.Button(\n            description='Send',\n            button_style='primary',\n            icon='paper-plane',\n            layout=widgets.Layout(width='10%', height='40px')\n        )\n        \n        # Clear button\n        self.clear_button = widgets.Button(\n            description='Clear',\n            button_style='warning',\n            icon='trash',\n            layout=widgets.Layout(width='10%', height='40px')\n        )\n        \n        # Stats button\n        self.stats_button = widgets.Button(\n            description='Stats',\n            button_style='info',\n            icon='bar-chart',\n            layout=widgets.Layout(width='10%', height='40px')\n        )\n        \n        # Help button\n        self.help_button = widgets.Button(\n            description='Help',\n            button_style='success',\n            icon='question',\n            layout=widgets.Layout(width='10%', height='40px')\n        )\n        \n        # Layout containers\n        self.input_row = widgets.HBox([\n            self.input_box,\n            self.send_button\n        ])\n        \n        self.button_row = widgets.HBox([\n            self.clear_button,\n            self.stats_button,\n            self.help_button\n        ])\n        \n        self.chat_container = widgets.VBox([\n            self.output,\n            self.input_row,\n            self.button_row\n        ])\n    \n    def _setup_handlers(self):\n        \"\"\"Setup event handlers\"\"\"\n        self.send_button.on_click(self._handle_send)\n        self.clear_button.on_click(self._handle_clear)\n        self.stats_button.on_click(self._handle_stats)\n        self.help_button.on_click(self._handle_help)\n        self.input_box.on_submit(lambda x: self._handle_send(None))\n    \n    def _handle_send(self, button):\n        \"\"\"Handle send button click\"\"\"\n        query = self.input_box.value.strip()\n        \n        if not query:\n            return\n        \n        # Clear input\n        self.input_box.value = \"\"\n        \n        # Show user message\n        user_html = self._format_user_message(query)\n        self.conversation_history.append(user_html)\n        \n        with self.output:\n            display(HTML(user_html))\n        \n        # Show thinking indicator\n        with self.output:\n            thinking_html = self._format_thinking_message()\n            display(HTML(thinking_html))\n        \n        # Get response\n        start_time = time.time()\n        response = self.agent.run(query)\n        elapsed = time.time() - start_time\n        \n        # Clear output and redisplay\n        self.output.clear_output(wait=True)\n        \n        # Redisplay all history\n        for msg in self.conversation_history:\n            with self.output:\n                display(HTML(msg))\n        \n        # Add agent response\n        agent_html = self._format_agent_message(response, elapsed)\n        self.conversation_history.append(agent_html)\n        \n        with self.output:\n            display(HTML(agent_html))\n    \n    def _handle_clear(self, button):\n        \"\"\"Handle clear button click\"\"\"\n        self.conversation_history = []\n        self.output.clear_output()\n        \n        with self.output:\n            display(HTML(self._format_system_message(\"Chat cleared. Start a new conversation!\")))\n    \n    def _handle_stats(self, button):\n        \"\"\"Handle stats button click\"\"\"\n        stats = self.agent.get_stats()\n        \n        stats_html = f\"\"\"\n        <div style='background:#e3f2fd;padding:15px;margin:10px 0;border-radius:8px;border-left:4px solid #2196F3;'>\n            <h3 style='margin:0 0 10px 0;color:#1976D2;'>üìä Statistics</h3>\n            <table style='width:100%;'>\n                <tr>\n                    <td><b>Total Queries:</b></td>\n                    <td>{stats['total_queries']}</td>\n                </tr>\n                <tr>\n                    <td><b>Successful:</b></td>\n                    <td>{stats['successful_queries']}</td>\n                </tr>\n                <tr>\n                    <td><b>Success Rate:</b></td>\n                    <td>{stats['success_rate']}%</td>\n                </tr>\n                <tr>\n                    <td><b>LLM Calls:</b></td>\n                    <td>{stats['llm_stats']['total_calls']}</td>\n                </tr>\n                <tr>\n                    <td><b>Avg Response Time:</b></td>\n                    <td>{stats['llm_stats']['avg_time']}s</td>\n                </tr>\n            </table>\n        </div>\n        \"\"\"\n        \n        with self.output:\n            display(HTML(stats_html))\n    \n    def _handle_help(self, button):\n        \"\"\"Handle help button click\"\"\"\n        help_html = \"\"\"\n        <div style='background:#fff3e0;padding:15px;margin:10px 0;border-radius:8px;border-left:4px solid #FF9800;'>\n            <h3 style='margin:0 0 10px 0;color:#F57C00;'>üìã Available Commands & Tools</h3>\n            <p><b>Tools:</b></p>\n            <ul>\n                <li><b>suggest_improvements</b> - Get model optimization suggestions</li>\n                <li><b>compare_architectures</b> - Compare different model architectures</li>\n                <li><b>debug_rle_masks</b> - Debug RLE encoding issues</li>\n                <li><b>create_strategy_plan</b> - Create strategic improvement plans</li>\n                <li><b>analyze_discussions</b> - Analyze competition discussions</li>\n            </ul>\n            <p><b>Example Questions:</b></p>\n            <ul>\n                <li>\"What's my current model and score?\"</li>\n                <li>\"Suggest 3 improvements for my model\"</li>\n                <li>\"Compare EfficientNet-B4 vs ResNet50\"</li>\n                <li>\"Create a 2-day plan to improve my score\"</li>\n                <li>\"Debug my RLE mask encoding error\"</li>\n            </ul>\n        </div>\n        \"\"\"\n        \n        with self.output:\n            display(HTML(help_html))\n    \n    def _format_user_message(self, text: str) -> str:\n        \"\"\"Format user message HTML\"\"\"\n        return f\"\"\"\n        <div style='background:#e3f2fd;padding:12px;margin:8px 0;border-radius:8px;border-left:4px solid #2196F3;'>\n            <div style='font-weight:bold;color:#1976D2;margin-bottom:5px;'>üë§ You</div>\n            <div style='color:#333;'>{text}</div>\n        </div>\n        \"\"\"\n    \n    def _format_agent_message(self, text: str, elapsed: float) -> str:\n        \"\"\"Format agent message HTML\"\"\"\n        return f\"\"\"\n        <div style='background:#c8e6c9;padding:12px;margin:8px 0;border-radius:8px;border-left:4px solid #4CAF50;'>\n            <div style='font-weight:bold;color:#2E7D32;margin-bottom:5px;'>\n                ü§ñ Agent <span style='font-weight:normal;color:#666;font-size:0.9em;'>(responded in {elapsed:.1f}s)</span>\n            </div>\n            <div style='color:#333;white-space:pre-wrap;'>{text}</div>\n        </div>\n        \"\"\"\n    \n    def _format_thinking_message(self) -> str:\n        \"\"\"Format thinking indicator HTML\"\"\"\n        return \"\"\"\n        <div style='background:#fff3e0;padding:12px;margin:8px 0;border-radius:8px;border-left:4px solid #FF9800;'>\n            <div style='font-weight:bold;color:#F57C00;'>ü§ñ Agent</div>\n            <div style='color:#666;'>Thinking...</div>\n        </div>\n        \"\"\"\n    \n    def _format_system_message(self, text: str) -> str:\n        \"\"\"Format system message HTML\"\"\"\n        return f\"\"\"\n        <div style='background:#f5f5f5;padding:12px;margin:8px 0;border-radius:8px;text-align:center;'>\n            <div style='color:#666;font-style:italic;'>{text}</div>\n        </div>\n        \"\"\"\n    \n    def show(self):\n        \"\"\"Display the chat interface\"\"\"\n        # Header\n        header_html = \"\"\"\n        <div style='background:linear-gradient(135deg, #667eea 0%, #764ba2 100%);color:white;padding:20px;border-radius:10px;margin-bottom:15px;box-shadow:0 4px 6px rgba(0,0,0,0.1);'>\n            <h1 style='margin:0 0 10px 0;font-size:28px;'>ü§ñ Image Forgery Assistant</h1>\n            <p style='margin:0;font-size:14px;opacity:0.9;'>AI-powered help for your Kaggle competition ‚Ä¢ Ask me anything!</p>\n            <div style='margin-top:10px;font-size:12px;opacity:0.8;'>\n                <span style='margin-right:15px;'>üë§ User: \"\"\" + self.agent.config['user_name'] + \"\"\"</span>\n                <span style='margin-right:15px;'>üéØ Score: \"\"\" + str(self.agent.config['current_score']) + \"\"\"</span>\n                <span>üìä Target: \"\"\" + str(self.agent.config['target_score']) + \"\"\"</span>\n            </div>\n        </div>\n        \"\"\"\n        \n        display(HTML(header_html))\n        \n        # Welcome message\n        with self.output:\n            welcome_html = \"\"\"\n            <div style='background:#e8f5e9;padding:15px;margin:10px 0;border-radius:8px;border-left:4px solid #4CAF50;'>\n                <h3 style='margin:0 0 10px 0;color:#2E7D32;'>üëã Welcome!</h3>\n                <p style='margin:0;color:#333;'>I'm your AI assistant for the Image Forgery Detection competition. Ask me anything about:</p>\n                <ul style='margin:10px 0 0 20px;color:#333;'>\n                    <li>Model improvements and optimizations</li>\n                    <li>Architecture comparisons</li>\n                    <li>Strategic planning</li>\n                    <li>Technical debugging</li>\n                    <li>Competition insights</li>\n                </ul>\n                <p style='margin:10px 0 0 0;color:#666;font-size:0.9em;'>üí° Tip: Click \"Help\" button for example questions!</p>\n            </div>\n            \"\"\"\n            display(HTML(welcome_html))\n        \n        # Display chat container\n        display(self.chat_container)\n\n\n# Initialize and show chat\nif agent:\n    chat = KaggleChat(agent)\n    chat.show()\nelse:\n    print(\"‚ö†Ô∏è Cannot initialize chat - agent unavailable\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nQuick functionality test\nRun this cell to verify everything works before using the chat\n\"\"\"\n\nprint(\"=\"*70)\nprint(\"  üß™ QUICK FUNCTIONALITY TEST\")\nprint(\"=\"*70)\n\nif not agent:\n    print(\"\\n‚ùå Agent not available - check API key configuration\")\nelse:\n    print(\"\\n‚úÖ Agent is ready\")\n    print(\"\\nTesting with a simple query...\")\n    \n    test_query = \"What's my current model and score?\"\n    print(f\"\\nQuery: {test_query}\")\n    print(\"\\nAgent: Thinking...\")\n    \n    start = time.time()\n    response = agent.run(test_query)\n    elapsed = time.time() - start\n    \n    print(f\"\\n‚úÖ Response (in {elapsed:.1f}s):\")\n    print(response[:200] + \"...\" if len(response) > 200 else response)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"‚úÖ Test complete! Scroll up to use the chat interface.\")\n    print(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nDirect API Usage Examples\nUse these if you prefer programmatic access instead of chat UI\n\"\"\"\n\n# Example 1: Simple query\nprint(\"=\"*70)\nprint(\"Example 1: Simple Query\")\nprint(\"=\"*70)\n\nresponse = agent.run(\"What's my current model?\")\nprint(response)\n\nprint(\"\\n\" + \"=\"*70)\n\n# Example 2: Using a specific tool\nprint(\"Example 2: Suggest Improvements\")\nprint(\"=\"*70)\n\nresponse = agent.run(\"Suggest 3 improvements for my EfficientNet-B4 model\")\nprint(response)\n\nprint(\"\\n\" + \"=\"*70)\n\n# Example 3: Architecture comparison\nprint(\"Example 3: Compare Architectures\")\nprint(\"=\"*70)\n\nresponse = agent.run(\"Compare EfficientNet-B4 vs ResNet50 for image segmentation\")\nprint(response)\n\nprint(\"\\n\" + \"=\"*70)\n\n# Show statistics\nprint(\"Statistics\")\nprint(\"=\"*70)\nstats = agent.get_stats()\nprint(f\"Total queries: {stats['total_queries']}\")\nprint(f\"Success rate: {stats['success_rate']}%\")\nprint(f\"Avg LLM response time: {stats['llm_stats']['avg_time']}s\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}